{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "classiify.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/restrepo/cms_pub/blob/main/classiify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Iz4OvjeUXx"
      },
      "source": [
        "# Machine learning classifier for CMS publications\n",
        "We use the CMS publications with the manual defined categories at:\n",
        "\n",
        "https://cms-results.web.cern.ch/cms-results/public-results/publications/\n",
        "\n",
        "to predict the category of a new CMS publication.\n",
        "\n",
        "We will follow the `NaiveBayesClassifier` tutorial from `textblob` at:\n",
        "\n",
        "https://textblob.readthedocs.io/en/dev/classifiers.html#classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTSDtWHMeUX0",
        "outputId": "048ba71b-071f-414e-f3fd-b9b2f72edbc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from textblob.classifiers import NaiveBayesClassifier\n",
        "nltk.download('punkt')  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njauBURneUX1"
      },
      "source": [
        "Load the data and prepare the training data set based in the title+abstract of each publication and the assigned category: `'CTG'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHUgUZUfeUX2"
      },
      "source": [
        "df=pd.read_json('https://raw.githubusercontent.com/restrepo/cms_pub/main/cms.json')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lS-b4CxeUX2"
      },
      "source": [
        "Sample of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDB2Bi5eUX2",
        "outputId": "6e87efd6-4849-452b-b652-8e8926c5caa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "df[:2]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CMS_id</th>\n",
              "      <th>report</th>\n",
              "      <th>title</th>\n",
              "      <th>journal</th>\n",
              "      <th>date</th>\n",
              "      <th>CTG</th>\n",
              "      <th>category</th>\n",
              "      <th>inspire_id</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>FSQ-16-006</td>\n",
              "      <td>Study of central exclusive $\\pi^{+}\\pi^{-}$ pr...</td>\n",
              "      <td>EPJC 80 (2020) 718</td>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>FSQ</td>\n",
              "      <td>Forward and Small-x QCD Physics</td>\n",
              "      <td>1784063</td>\n",
              "      <td>Central exclusive and semiexclusive production...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>FSQ-12-033</td>\n",
              "      <td>Measurement of single-diffractive dijet produc...</td>\n",
              "      <td>EPJC 80, 1164 (2020)</td>\n",
              "      <td>2020-02-27</td>\n",
              "      <td>FSQ</td>\n",
              "      <td>Forward and Small-x QCD Physics</td>\n",
              "      <td>1782637</td>\n",
              "      <td>Measurements are presented of the single-diffr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CMS_id  ...                                           abstract\n",
              "0      58  ...  Central exclusive and semiexclusive production...\n",
              "1      57  ...  Measurements are presented of the single-diffr...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqqqhgu1eUX3"
      },
      "source": [
        "Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw6_yj9ReUX3",
        "outputId": "c6df60b6-e9e6-4e6f-886e-63ff1e2be4ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df=df[df['abstract'].fillna('')!=''].reset_index(drop=True)\n",
        "df['text']=df['title']+' '+df['abstract']\n",
        "df=df.rename({'CTG':'label'},axis='columns')\n",
        "\n",
        "stop_words=stopwords.words()\n",
        "def simplify(text,stop_words=stop_words):\n",
        "    text_tokens = text.replace(\"  \",\" \").split()\n",
        "    filtered_words = [w for w in text_tokens if not w in stop_words]    \n",
        "    return \" \".join(filtered_words).lower()\n",
        "\n",
        "df['text']=df['text'].apply(simplify)\n",
        "\n",
        "print('total publication count:',df.shape[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total publication count: 912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmj6LmC0eUX4"
      },
      "source": [
        "shuffle the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_zLiNeYeUX4"
      },
      "source": [
        "dfr=df.sample(df.shape[0])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYxC_JrxeUYA"
      },
      "source": [
        "Calculate the accuracy of the trained dataset, `train`, with the `test` one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhVu3iVfeUYB",
        "outputId": "fab4c405-a9d0-44c5-edc0-7996bef05e5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_train=800\n",
        "train=dfr[['text','label']][:n_train].reset_index(drop=True)\n",
        "test =dfr[['text','label']][n_train:].reset_index(drop=True)\n",
        "\n",
        "#Obtain the classifier with the `train` dataset\n",
        "cl = NaiveBayesClassifier(  \n",
        "    [ (d.get('text'),d.get('label')) for d in train.to_dict(orient='records')]  )\n",
        "\n",
        "# Check the accuracy of the classifier with the `test` dataset\n",
        "print('accuracy → ',\n",
        "      round( cl.accuracy( [ (d.get('text'),d.get('label')) for d in test.to_dict(orient='records')] ),2)\n",
        "     )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy →  0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtfXbqs_eUYC"
      },
      "source": [
        "Partial accuracies: there are several at the 90% level. Those would correspond to well defined categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3KpIModeUYC",
        "outputId": "d110448d-fe8e-4d7c-acb4-0671caf68d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for c in test['label'].unique():\n",
        "    print(c,'→',\n",
        "          round(cl.accuracy( [ (d.get('text'),d.get('label')) for d in test[test['label']==c].to_dict(orient='records')]),2),\n",
        "          f\" samples → {test[test['label']==c].shape[0]}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FSQ → 0.5  samples → 6\n",
            "SMP → 0.93  samples → 15\n",
            "SUS → 0.75  samples → 12\n",
            "EXO → 0.93  samples → 27\n",
            "TOP → 0.75  samples → 12\n",
            "HIN → 1.0  samples → 9\n",
            "HIG → 0.88  samples → 17\n",
            "BPH → 0.62  samples → 8\n",
            "B2G → 0.33  samples → 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RArdEwjfeUYD"
      },
      "source": [
        "Check explicit results including the probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX2Q7QSNeUYD"
      },
      "source": [
        "fulltest=test.copy()\n",
        "fulltest['test']=fulltest['text'].apply(cl.classify)\n",
        "\n",
        "fulltest['prob']=fulltest['text'].apply(lambda t:   \n",
        "                                cl.prob_classify( t ).prob(   cl.classify( t  )  ) ).round(2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze7SFyVEeUYD"
      },
      "source": [
        "Show the ones that failed.\n",
        "The following categories are expected to be mixed between them\n",
        "\n",
        "* `[B2G,EXO,SUS]`\n",
        "* `[HIG,TOP,SMP,FSQ]`\n",
        "\n",
        "In this way, the errors are easy to understand. \n",
        "\n",
        "__Hypothesis__: The network analysis would have this failed publications in the frontiers of the clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMZ_ROrZeUYE",
        "outputId": "9cf48812-aebe-4fb5-bb96-dd71a06dd4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "source": [
        "fulltest[fulltest['label']!=fulltest['test']]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>test</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exclusive semi-exclusive $\\pi^{+}\\pi^{-}$ prod...</td>\n",
              "      <td>FSQ</td>\n",
              "      <td>SMP</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>search dark matter supersymmetry compressed ma...</td>\n",
              "      <td>SUS</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>search anomalous single top quark production a...</td>\n",
              "      <td>TOP</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>observation diffractive contribution dijet pro...</td>\n",
              "      <td>FSQ</td>\n",
              "      <td>SMP</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>search massive resonance decaying higgs boson ...</td>\n",
              "      <td>EXO</td>\n",
              "      <td>B2G</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>study bose-einstein correlations pp, ppb, pbpb...</td>\n",
              "      <td>FSQ</td>\n",
              "      <td>HIN</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>search $s$ channel single top quark production...</td>\n",
              "      <td>TOP</td>\n",
              "      <td>HIG</td>\n",
              "      <td>0.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>measurement $ \\lambda_{\\mathrm{b}} $ polarizat...</td>\n",
              "      <td>BPH</td>\n",
              "      <td>SMP</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>combination searches heavy resonances decaying...</td>\n",
              "      <td>B2G</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>search $r$-parity violating supersymmetry disp...</td>\n",
              "      <td>SUS</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>search massive resonances dijet systems contai...</td>\n",
              "      <td>EXO</td>\n",
              "      <td>B2G</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>a deep neural network simultaneous estimation ...</td>\n",
              "      <td>HIG</td>\n",
              "      <td>TOP</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>constraints models scalar vector leptoquarks d...</td>\n",
              "      <td>SUS</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>measurement inclusive differential higgs boson...</td>\n",
              "      <td>HIG</td>\n",
              "      <td>SMP</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>search pair production excited top quarks lept...</td>\n",
              "      <td>B2G</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>measurement cross section production b b-bar x...</td>\n",
              "      <td>BPH</td>\n",
              "      <td>SMP</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>search $\\mathrm{ \\bar{t} }$ resonances highly-...</td>\n",
              "      <td>B2G</td>\n",
              "      <td>EXO</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>search monotop signatures proton-proton collis...</td>\n",
              "      <td>B2G</td>\n",
              "      <td>EXO</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>measurement $\\lambda_b^0$ lifetime pp collisio...</td>\n",
              "      <td>BPH</td>\n",
              "      <td>SMP</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>search anomalous electroweak production vector...</td>\n",
              "      <td>SMP</td>\n",
              "      <td>HIG</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>search flavor-changing neutral current interac...</td>\n",
              "      <td>TOP</td>\n",
              "      <td>HIG</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text label test  prob\n",
              "0    exclusive semi-exclusive $\\pi^{+}\\pi^{-}$ prod...   FSQ  SMP  1.00\n",
              "2    search dark matter supersymmetry compressed ma...   SUS  EXO  1.00\n",
              "8    search anomalous single top quark production a...   TOP  EXO  1.00\n",
              "9    observation diffractive contribution dijet pro...   FSQ  SMP  0.98\n",
              "11   search massive resonance decaying higgs boson ...   EXO  B2G  1.00\n",
              "12   study bose-einstein correlations pp, ppb, pbpb...   FSQ  HIN  1.00\n",
              "18   search $s$ channel single top quark production...   TOP  HIG  0.98\n",
              "19   measurement $ \\lambda_{\\mathrm{b}} $ polarizat...   BPH  SMP  0.57\n",
              "21   combination searches heavy resonances decaying...   B2G  EXO  1.00\n",
              "22   search $r$-parity violating supersymmetry disp...   SUS  EXO  1.00\n",
              "24   search massive resonances dijet systems contai...   EXO  B2G  0.91\n",
              "41   a deep neural network simultaneous estimation ...   HIG  TOP  0.97\n",
              "43   constraints models scalar vector leptoquarks d...   SUS  EXO  1.00\n",
              "54   measurement inclusive differential higgs boson...   HIG  SMP  1.00\n",
              "66   search pair production excited top quarks lept...   B2G  EXO  1.00\n",
              "67   measurement cross section production b b-bar x...   BPH  SMP  1.00\n",
              "70   search $\\mathrm{ \\bar{t} }$ resonances highly-...   B2G  EXO  0.93\n",
              "85   search monotop signatures proton-proton collis...   B2G  EXO  1.00\n",
              "87   measurement $\\lambda_b^0$ lifetime pp collisio...   BPH  SMP  1.00\n",
              "96   search anomalous electroweak production vector...   SMP  HIG  1.00\n",
              "104  search flavor-changing neutral current interac...   TOP  HIG  1.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjejdTS4fBD4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}